{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LinearRegression\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/wangxiaoyang/opt/anaconda3/lib/python3.8/site-packages/pandas/core/frame.py:3990: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  return super().drop(\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv('WMT1.csv')\n",
    "data_17 = data[data.Year == 2017]\n",
    "\n",
    "# calculate the mean std\n",
    "mean_17 = data_17.groupby('Week_Number')['Return'].mean().tolist()\n",
    "std_17 = data_17.groupby('Week_Number')['Return'].std().tolist()\n",
    "week_id_17 = list(data_17.groupby('Week_Number').indices.keys())\n",
    "color_17 = data_17.groupby('Week_Number')['label'].agg(lambda x: x.mode()).tolist()\n",
    "\n",
    "data_18 = data[data.Year == 2018]\n",
    "data_18.drop(data_18.index[-1], inplace=True)\n",
    "\n",
    "# calculate the mean std\n",
    "mean_18 = data_18.groupby('Week_Number')['Return'].mean().tolist()\n",
    "std_18 = data_18.groupby('Week_Number')['Return'].std().tolist()\n",
    "weekly_18 = data[(data.Year == 2018) & (data.Weekday == 'Friday')]['Adj Close'].values  # select Friday's data\n",
    "\n",
    "week_id_18 = list(data_18.groupby('Week_Number').indices.keys())\n",
    "color_18 = data_18.groupby('Week_Number')['label'].agg(lambda x: x.mode()).tolist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "delta1_list = []\n",
    "delta2_list = []\n",
    "delta3_list = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "# logistic regression\n",
    "x_train = list(zip(mean_17,std_17))\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(x_train)\n",
    "x_train = scaler.transform(x_train)\n",
    "y_train = color_17\n",
    "\n",
    "x_test = list(zip(mean_18,std_18))\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(x_test)\n",
    "x_test = scaler.transform(x_test)\n",
    "y_test = color_18\n",
    "\n",
    "log_reg_classifier = LogisticRegression()\n",
    "log_reg_classifier.fit(x_train,y_train)\n",
    "prediction = log_reg_classifier.predict(x_test)\n",
    "accuracy = log_reg_classifier.score(x_test,y_test)\n",
    "##########################################\n",
    "\n",
    "x_train_1 = np.array(mean_17).reshape(-1, 1)\n",
    "y_train_1 = color_17\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(x_train_1)\n",
    "x_train_1 = scaler.transform(x_train_1)\n",
    "\n",
    "x_test_1 = np.array(mean_18).reshape(-1, 1)\n",
    "y_test_1 = color_18\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(x_test_1)\n",
    "x_test_1 = scaler.transform(x_test_1)\n",
    "\n",
    "log_reg_classifier = LogisticRegression()\n",
    "log_reg_classifier.fit(x_train_1,y_train_1)\n",
    "prediction = log_reg_classifier.predict(x_test_1)\n",
    "accuracy1 = log_reg_classifier.score(x_test_1,y_test_1)\n",
    "\n",
    "delta1 = accuracy - accuracy1\n",
    "delta1_list.append(delta1)\n",
    "#############################################\n",
    "x_train_2 = np.array(std_17).reshape(-1, 1)\n",
    "y_train_2 = color_17\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(x_train_2)\n",
    "x_train_2 = scaler.transform(x_train_2)\n",
    "\n",
    "x_test_2 = np.array(std_18).reshape(-1, 1)\n",
    "y_test_2 = color_18\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(x_test_2)\n",
    "x_test_2 = scaler.transform(x_test_2)\n",
    "\n",
    "log_reg_classifier = LogisticRegression()\n",
    "log_reg_classifier.fit(x_train_2,y_train_2)\n",
    "prediction = log_reg_classifier.predict(x_test_2)\n",
    "accuracy2 = log_reg_classifier.score(x_test_2,y_test_2)\n",
    "\n",
    "delta2 = accuracy - accuracy2\n",
    "delta1_list.append(delta2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.0, 0.2692307692307693]"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "delta1_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "# knn\n",
    "x_train = list(zip(mean_17,std_17))\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(x_train)\n",
    "x_train = scaler.transform(x_train)\n",
    "y_train = color_17\n",
    "\n",
    "x_test = list(zip(mean_18,std_18))\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(x_test)\n",
    "x_test = scaler.transform(x_test)\n",
    "y_test = color_18\n",
    "\n",
    "knn_classifier = KNeighborsClassifier(n_neighbors = 3)\n",
    "knn_classifier.fit(x_train,y_train)\n",
    "prediction = knn_classifier.predict(x_test)\n",
    "accuracy = knn_classifier.score(x_test,y_test)\n",
    "##########################################\n",
    "\n",
    "x_train_1 = np.array(mean_17).reshape(-1, 1)\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(x_train_1)\n",
    "x_train_1 = scaler.transform(x_train_1)\n",
    "y_train_1 = color_17\n",
    "\n",
    "\n",
    "x_test_1 = np.array(mean_18).reshape(-1, 1)\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(x_test_1)\n",
    "x_test_1 = scaler.transform(x_test_1)\n",
    "\n",
    "y_test_1 = color_18\n",
    "\n",
    "\n",
    "knn_classifier = KNeighborsClassifier(n_neighbors = 3)\n",
    "knn_classifier.fit(x_train_1,y_train_1)\n",
    "prediction = knn_classifier.predict(x_test_1)\n",
    "accuracy1 = knn_classifier.score(x_test_1,y_test_1)\n",
    "\n",
    "delta1 = accuracy - accuracy1\n",
    "delta2_list.append(delta1)\n",
    "#############################################\n",
    "x_train_2 = np.array(std_17).reshape(-1, 1)\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(x_train_2)\n",
    "x_train_2 = scaler.transform(x_train_2)\n",
    "y_train_2 = color_17\n",
    "\n",
    "\n",
    "x_test_2 = np.array(std_18).reshape(-1, 1)\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(x_test_2)\n",
    "x_test_2 = scaler.transform(x_test_2)\n",
    "y_test_2 = color_18\n",
    "\n",
    "\n",
    "knn_classifier = KNeighborsClassifier(n_neighbors = 3)\n",
    "knn_classifier.fit(x_train_2,y_train_2)\n",
    "prediction = knn_classifier.predict(x_test_2)\n",
    "accuracy2 = knn_classifier.score(x_test_2,y_test_2)\n",
    "\n",
    "delta2 = accuracy - accuracy2\n",
    "delta2_list.append(delta2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "# linear\n",
    "\n",
    "x_train = np.array(list(zip(mean_17,std_17)))\n",
    "# scaler = StandardScaler()\n",
    "# scaler.fit(x_train)\n",
    "# x_train = scaler.transform(x_train)\n",
    "y_train = []\n",
    "for i in color_17:\n",
    "    if i =='red':\n",
    "        y_train.append(0)\n",
    "    else:\n",
    "        y_train.append(1)\n",
    "        \n",
    "x_test = list(zip(mean_18,std_18))\n",
    "# scaler = StandardScaler()\n",
    "# scaler.fit(x_test)\n",
    "# x_test = scaler.transform(x_test)\n",
    "y_test = []\n",
    "for i in color_18:\n",
    "    if i =='red':\n",
    "        y_test.append(0)\n",
    "    else:\n",
    "        y_test.append(1)\n",
    "\n",
    "lin_reg = LinearRegression(fit_intercept = True )\n",
    "lin_reg.fit(x_train , y_train)\n",
    "prediction = lin_reg.predict(x_test)\n",
    "a = np.where(prediction>0 ,1,0)\n",
    "accuracy = 1 - np.mean(y_test != a)\n",
    "\n",
    "##########################################\n",
    "x_train_1 = np.array(mean_17)\n",
    "\n",
    "y_train_1 = y_train\n",
    "\n",
    "x_test_1 = np.array(mean_18)\n",
    "\n",
    "y_test_1 = y_test\n",
    "\n",
    "\n",
    "degree = 1\n",
    "\n",
    "weights = np.polyfit(x_train_1,y_train_1,degree)\n",
    "model = np.poly1d(weights)\n",
    "\n",
    "prediction = model(x_test_1)\n",
    "a = np.where(prediction>0 ,1,0)\n",
    "\n",
    "accuracy1 = 1 - np.mean(y_test_1 != a)\n",
    "\n",
    "delta1 = accuracy - accuracy1\n",
    "delta3_list.append(delta1)\n",
    "#############################################\n",
    "x_train_2 = np.array(std_17)\n",
    "\n",
    "y_train_2 = y_train\n",
    "\n",
    "\n",
    "x_test_2 = np.array(std_18)\n",
    "\n",
    "y_test_2 = y_test\n",
    "\n",
    "\n",
    "degree = 1\n",
    "weights = np.polyfit(x_train_1,y_train_1,degree)\n",
    "model = np.poly1d(weights)\n",
    "prediction = model(x_test_2)\n",
    "a = np.where(prediction>0 ,1,0)\n",
    "\n",
    "accuracy2 = 1 - np.mean(y_test_2 != a)\n",
    "\n",
    "delta2 = accuracy - accuracy2\n",
    "delta3_list.append(delta2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>para</th>\n",
       "      <th>lr</th>\n",
       "      <th>knn(n=3)</th>\n",
       "      <th>linear(d=1)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>mean</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.038462</td>\n",
       "      <td>0.038462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>std</td>\n",
       "      <td>0.269231</td>\n",
       "      <td>0.269231</td>\n",
       "      <td>0.192308</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   para        lr  knn(n=3)  linear(d=1)\n",
       "0  mean  0.000000 -0.038462     0.038462\n",
       "1   std  0.269231  0.269231     0.192308"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_result = pd.DataFrame(\n",
    "    {\n",
    "        'para':['mean','std'],\n",
    "        'lr':delta1_list,\n",
    "        'knn(n=3)':delta2_list,\n",
    "        'linear(d=1)':delta3_list\n",
    "    },\n",
    "    columns = ['para','lr','knn(n=3)','linear(d=1)'],\n",
    ")\n",
    "df_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "iris = load_iris()\n",
    "df = pd.DataFrame(iris.data, columns=iris.feature_names)\n",
    "df['label'] = iris.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_name = []\n",
    "for i in iris.target:\n",
    "    if i == 0:\n",
    "        target_name.append('setosa')\n",
    "    elif i == 1:\n",
    "        target_name.append('versicolor')\n",
    "    elif i ==2:\n",
    "        target_name.append('virginica')\n",
    "df['label'] = target_name\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-0.04, 0.03, -0.04, -0.03]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#versicolor\n",
    "delta_list_versicolor = []\n",
    "features = df[['sepal length (cm)','sepal width (cm)','petal length (cm)','petal width (cm)']]\n",
    "classes = []\n",
    "label = df['label'].to_list()\n",
    "for i in label:\n",
    "    if i == 'setosa' or i == 'virginica':\n",
    "        classes.append(0)\n",
    "    else:\n",
    "        classes.append(1)\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(features)\n",
    "features = scaler.transform(features)\n",
    "\n",
    "x_train,x_test,y_train,y_test = train_test_split(features,classes,test_size = 0.5,random_state = 3)\n",
    "\n",
    "log_reg_classifier = LogisticRegression()\n",
    "log_reg_classifier.fit(x_train,y_train)\n",
    "prediction = log_reg_classifier.predict(x_test)\n",
    "accuracy = 1 - np.mean(prediction != y_test)\n",
    "\n",
    "#############\n",
    "features1 = df[['sepal width (cm)','petal length (cm)','petal width (cm)']]\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(features1)\n",
    "features1 = scaler.transform(features1)\n",
    "\n",
    "x_train,x_test,y_train,y_test = train_test_split(features1,classes,test_size = 0.5,random_state = 3)\n",
    "\n",
    "log_reg_classifier = LogisticRegression()\n",
    "log_reg_classifier.fit(x_train,y_train)\n",
    "prediction = log_reg_classifier.predict(x_test)\n",
    "accuracy1 = 1 - np.mean(prediction != y_test)\n",
    "delta1 = round((accuracy - accuracy1),2)\n",
    "delta_list_versicolor.append(delta1)\n",
    "#############\n",
    "features2 = df[['sepal length (cm)','petal length (cm)','petal width (cm)']]\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(features2)\n",
    "features2 = scaler.transform(features2)\n",
    "\n",
    "x_train,x_test,y_train,y_test = train_test_split(features2,classes,test_size = 0.5,random_state = 3)\n",
    "\n",
    "log_reg_classifier = LogisticRegression()\n",
    "log_reg_classifier.fit(x_train,y_train)\n",
    "prediction = log_reg_classifier.predict(x_test)\n",
    "accuracy2 = 1 - np.mean(prediction != y_test)\n",
    "delta2 = round((accuracy - accuracy2),2)\n",
    "delta_list_versicolor.append(delta2)\n",
    "\n",
    "#############\n",
    "features3 = df[['sepal length (cm)','sepal width (cm)','petal width (cm)']]\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(features3)\n",
    "features3 = scaler.transform(features3)\n",
    "x_train,x_test,y_train,y_test = train_test_split(features3,classes,test_size = 0.5,random_state = 3)\n",
    "\n",
    "log_reg_classifier = LogisticRegression()\n",
    "log_reg_classifier.fit(x_train,y_train)\n",
    "prediction = log_reg_classifier.predict(x_test)\n",
    "accuracy3 = 1 - np.mean(prediction != y_test)\n",
    "delta3 = round((accuracy - accuracy3),2)\n",
    "delta_list_versicolor.append(delta3)\n",
    "\n",
    "############\n",
    "features4 = df[['sepal length (cm)','sepal width (cm)','petal length (cm)']]\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(features4)\n",
    "features1 = scaler.transform(features4)\n",
    "x_train,x_test,y_train,y_test = train_test_split(features4,classes,test_size = 0.5,random_state = 3)\n",
    "\n",
    "log_reg_classifier = LogisticRegression()\n",
    "log_reg_classifier.fit(x_train,y_train)\n",
    "prediction = log_reg_classifier.predict(x_test)\n",
    "accuracy4 = 1 - np.mean(prediction != y_test)\n",
    "delta4 = round((accuracy - accuracy4),2)\n",
    "delta_list_versicolor.append(delta4)\n",
    "delta_list_versicolor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.0, 0.0, 0.01, 0.0]"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#setosa\n",
    "delta_list_setosa = []\n",
    "features = df[['sepal length (cm)','sepal width (cm)','petal length (cm)','petal width (cm)']]\n",
    "classes = []\n",
    "label = df['label'].to_list()\n",
    "for i in label:\n",
    "    if i == 'versicolor' or i == 'virginica':\n",
    "        classes.append(0)\n",
    "    else:\n",
    "        classes.append(1)\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(features)\n",
    "features = scaler.transform(features)\n",
    "\n",
    "x_train,x_test,y_train,y_test = train_test_split(features,classes,test_size = 0.5,random_state = 3)\n",
    "\n",
    "log_reg_classifier = LogisticRegression()\n",
    "log_reg_classifier.fit(x_train,y_train)\n",
    "prediction = log_reg_classifier.predict(x_test)\n",
    "accuracy = 1 - np.mean(prediction != y_test)\n",
    "\n",
    "#############\n",
    "features1 = df[['sepal width (cm)','petal length (cm)','petal width (cm)']]\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(features1)\n",
    "features1 = scaler.transform(features1)\n",
    "x_train,x_test,y_train,y_test = train_test_split(features1,classes,test_size = 0.5,random_state = 3)\n",
    "\n",
    "log_reg_classifier = LogisticRegression()\n",
    "log_reg_classifier.fit(x_train,y_train)\n",
    "prediction = log_reg_classifier.predict(x_test)\n",
    "accuracy1 = 1 - np.mean(prediction != y_test)\n",
    "delta1 = round((accuracy - accuracy1),2)\n",
    "delta_list_setosa.append(delta1)\n",
    "#############\n",
    "features2 = df[['sepal length (cm)','petal length (cm)','petal width (cm)']]\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(features2)\n",
    "features2 = scaler.transform(features2)\n",
    "x_train,x_test,y_train,y_test = train_test_split(features2,classes,test_size = 0.5,random_state = 3)\n",
    "\n",
    "log_reg_classifier = LogisticRegression()\n",
    "log_reg_classifier.fit(x_train,y_train)\n",
    "prediction = log_reg_classifier.predict(x_test)\n",
    "accuracy2 = 1 - np.mean(prediction != y_test)\n",
    "delta2 = round((accuracy - accuracy2),2)\n",
    "delta_list_setosa.append(delta2)\n",
    "\n",
    "#############\n",
    "features3 = df[['sepal length (cm)','sepal width (cm)','petal width (cm)']]\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(features3)\n",
    "features3 = scaler.transform(features3)\n",
    "x_train,x_test,y_train,y_test = train_test_split(features3,classes,test_size = 0.5,random_state = 3)\n",
    "\n",
    "log_reg_classifier = LogisticRegression()\n",
    "log_reg_classifier.fit(x_train,y_train)\n",
    "prediction = log_reg_classifier.predict(x_test)\n",
    "accuracy3 = 1 - np.mean(prediction != y_test)\n",
    "delta3 = round((accuracy - accuracy3),2)\n",
    "delta_list_setosa.append(delta3)\n",
    "\n",
    "############\n",
    "features4 = df[['sepal length (cm)','sepal width (cm)','petal length (cm)']]\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(features4)\n",
    "features4 = scaler.transform(features4)\n",
    "x_train,x_test,y_train,y_test = train_test_split(features4,classes,test_size = 0.5,random_state = 3)\n",
    "\n",
    "log_reg_classifier = LogisticRegression()\n",
    "log_reg_classifier.fit(x_train,y_train)\n",
    "prediction = log_reg_classifier.predict(x_test)\n",
    "accuracy4 = 1 - np.mean(prediction != y_test)\n",
    "delta4 = round((accuracy - accuracy4),2)\n",
    "delta_list_setosa.append(delta4)\n",
    "delta_list_setosa\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.0, 0.0, 0.0, 0.05]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#virginica\n",
    "delta_list_virginica = []\n",
    "features = df[['sepal length (cm)','sepal width (cm)','petal length (cm)','petal width (cm)']]\n",
    "classes = []\n",
    "label = df['label'].to_list()\n",
    "for i in label:\n",
    "    if i == 'versicolor' or i == 'setosa':\n",
    "        classes.append(0)\n",
    "    else:\n",
    "        classes.append(1)\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(features)\n",
    "features = scaler.transform(features)\n",
    "x_train,x_test,y_train,y_test = train_test_split(features,classes,test_size = 0.5,random_state = 3)\n",
    "\n",
    "log_reg_classifier = LogisticRegression()\n",
    "log_reg_classifier.fit(x_train,y_train)\n",
    "prediction = log_reg_classifier.predict(x_test)\n",
    "accuracy = 1 - np.mean(prediction != y_test)\n",
    "\n",
    "#############\n",
    "features1 = df[['sepal width (cm)','petal length (cm)','petal width (cm)']]\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(features1)\n",
    "features1 = scaler.transform(features1)\n",
    "x_train,x_test,y_train,y_test = train_test_split(features1,classes,test_size = 0.5,random_state = 3)\n",
    "\n",
    "log_reg_classifier = LogisticRegression()\n",
    "log_reg_classifier.fit(x_train,y_train)\n",
    "prediction = log_reg_classifier.predict(x_test)\n",
    "accuracy1 = 1 - np.mean(prediction != y_test)\n",
    "delta1 = round((accuracy - accuracy1),2)\n",
    "delta_list_virginica.append(delta1)\n",
    "#############\n",
    "features2 = df[['sepal length (cm)','petal length (cm)','petal width (cm)']]\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(features2)\n",
    "features2 = scaler.transform(features2)\n",
    "x_train,x_test,y_train,y_test = train_test_split(features2,classes,test_size = 0.5,random_state = 3)\n",
    "\n",
    "log_reg_classifier = LogisticRegression()\n",
    "log_reg_classifier.fit(x_train,y_train)\n",
    "prediction = log_reg_classifier.predict(x_test)\n",
    "accuracy2 = 1 - np.mean(prediction != y_test)\n",
    "delta2 = round((accuracy - accuracy2),2)\n",
    "delta_list_virginica.append(delta2)\n",
    "\n",
    "#############\n",
    "features3 = df[['sepal length (cm)','sepal width (cm)','petal width (cm)']]\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(features3)\n",
    "features3 = scaler.transform(features3)\n",
    "x_train,x_test,y_train,y_test = train_test_split(features3,classes,test_size = 0.5,random_state = 3)\n",
    "\n",
    "log_reg_classifier = LogisticRegression()\n",
    "log_reg_classifier.fit(x_train,y_train)\n",
    "prediction = log_reg_classifier.predict(x_test)\n",
    "accuracy3 = 1 - np.mean(prediction != y_test)\n",
    "delta3 = round((accuracy - accuracy3),2)\n",
    "delta_list_virginica.append(delta3)\n",
    "\n",
    "############\n",
    "features4 = df[['sepal length (cm)','sepal width (cm)','petal length (cm)']]\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(features4)\n",
    "features4 = scaler.transform(features4)\n",
    "x_train,x_test,y_train,y_test = train_test_split(features4,classes,test_size = 0.5,random_state = 3)\n",
    "\n",
    "log_reg_classifier = LogisticRegression()\n",
    "log_reg_classifier.fit(x_train,y_train)\n",
    "prediction = log_reg_classifier.predict(x_test)\n",
    "accuracy4 = 1 - np.mean(prediction != y_test)\n",
    "delta4 = round((accuracy - accuracy4),2)\n",
    "delta_list_virginica.append(delta4)\n",
    "delta_list_virginica\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "title = []\n",
    "for i in iris.feature_names:\n",
    "    title.append(i+'Δ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Flower</th>\n",
       "      <th>versicolor</th>\n",
       "      <th>setosa</th>\n",
       "      <th>virginica</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sepal length (cm)Δ</td>\n",
       "      <td>-0.04</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sepal width (cm)Δ</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>petal length (cm)Δ</td>\n",
       "      <td>-0.04</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>petal width (cm)Δ</td>\n",
       "      <td>-0.03</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.05</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Flower  versicolor  setosa  virginica\n",
       "0  sepal length (cm)Δ       -0.04    0.00       0.00\n",
       "1   sepal width (cm)Δ        0.03    0.00       0.00\n",
       "2  petal length (cm)Δ       -0.04    0.01       0.00\n",
       "3   petal width (cm)Δ       -0.03    0.00       0.05"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_result_1 = pd.DataFrame(\n",
    "    {\n",
    "        'Flower':title,\n",
    "        'versicolor':delta_list_versicolor,\n",
    "        'setosa':delta_list_setosa,\n",
    "        'virginica':delta_list_virginica\n",
    "    },\n",
    "    columns = ['Flower','versicolor','setosa','virginica'],\n",
    ")\n",
    "df_result_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
